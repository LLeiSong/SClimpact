---
title: "Set up HPC environment"
author: "Lei Song"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
```

## Center for Scientific Computing HPC at UCSB

### knot7

**address**: knot7.cnsi.ucsb.edu

**Resources**:

[1-86]: batch nodes
[1]: with 1 hour time limit for jobs
[91-94]: Fat memory nodes

```
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
batch*       up   infinite      1 drain* node54
batch*       up   infinite     29  down* node[3,10,19,27,32,43,50,60,66-86]
batch*       up   infinite      4  drain node[4,8,15,51]
batch*       up   infinite     39  alloc node[7,9,11-14,16-18,20-23,25,28-29,31,33-42,46-48,52,56-59,62-65]
batch*       up   infinite      9   down node[2,5,24,26,30,49,53,55,61]
short        up    1:00:00      1   down node6
largemem     up 32-00:00:0      2  down* node[93-94]
largemem     up 32-00:00:0      1    mix node92
largemem     up 32-00:00:0      1  alloc node91
```

### pod (newer)

**address**: pod-login1.cnsi.ucsb.edu

**Resources**:

**Storage**:

- /scratch: 19TB RAID0 scratch
- /bigscratch: 70TB NVMe RAID0 scratch

**Nodes**:

[1-64]: dual 20 cores
[56, 64]: with 2 hours time limit for jobs
[101-104]: dual 20 cores with 1.4T RAM
[111-113,115-125]: 4 NVIDIA 64-bit V100 GPUs 40GB RAM

```
PARTITION AVAIL  TIMELIMIT  NODES  STATE NODELIST
batch*       up 58-08:00:0      1  drain node54
batch*       up 58-08:00:0     22    mix node[7-8,14-17,19,22-25,27-28,33,35-36,38,41-43,46,55]
batch*       up 58-08:00:0     39  alloc node[1-6,9-13,18,20-21,26,29-32,34,37,39-40,44-45,47-53,57-63]
short        up    2:00:00      1  alloc node56
short        up    2:00:00      1   idle node64
largemem     up 37-12:00:0      1  drain node103
largemem     up 37-12:00:0      3    mix node[101-102,104]
gpu          up 10-00:00:0     14    mix node[111-113,115-125]
aws          up    2:00:00      1 drain* aws-node-8
aws          up    2:00:00      3  drain aws-node-[6-7,10]
aws          up    2:00:00      4  idle~ aws-node-[1-4]
aws          up    2:00:00      2  down~ aws-node-[5,9]
```

## Set up the conda environment

### Step 1: Save login configuration

This step is optional, but it will significantly improve communication with the cluster. It saves your local machine's unique key on the cluster, allowing you to log in without needing to enter a password.

If you are unsure whether you've already created a key, you can follow this [tutorial](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/checking-for-existing-ssh-keys) to check. If necessary, you can follow this [tutorial](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent) to generate a new one.

Once you have your public key, you can add it to the authorized keys on the cluster by running the command on your local machine:

```
cat ~/.ssh/id_rsa.pub | ssh USER@HOST "mkdir -p ~/.ssh && cat >> ~/.ssh/authorized_keys"
```

### Step 2: Install anaconda3

If you don't have conda to manage your working environment, install it by following these steps (based on the [documentation](https://docs.anaconda.com/anaconda/install/linux/)):

```
curl -O https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh
bash ~/Anaconda3-2024.02-1-Linux-x86_64.sh
rm ~/Anaconda3-2024.02-1-Linux-x86_64.sh

source ~/anaconda3/bin/activate
conda init

conda list # verify the installation
```

### Step 3: Create the conda environment

Create a conda environment named sdm.

```
conda create -n sdm # create
conda activate sdm # activate, "conda deactivate" to log out
```


Install R, R spatial packages and R essentials

Note: Due to issues with the SQLite library, these steps have been tested to ensure all packages are installed correctly and function as expected.

```
conda install conda-forge::r-base
conda install conda-forge::r-terra
conda install conda-forge::libsqlite --force-reinstall
conda install conda-forge::r-codetools
conda install conda-forge::r-sf
conda install conda-forge::r-gdalutilities
conda install conda-forge::r-essentials
```

Install other essential R packages

```
conda install -c conda-forge r-fastshap r-optparse r-readxl r-rgbif r-here r-devtools
```

### Step 4: Install some public GitHub repo

It is not recommended to mix-use conda-forge and base R package installation due to potential risks, but it does work.

`occTest` and `megaSDM`:

```
# In command line
conda install anaconda::gfortran_linux-64

# Get in R environment
devtools::install_github("pepbioalerts/occTest")
devtools::install_github("brshipley/megaSDM")
```

### Step 5: Add GitHub credential

Follow the [tutorial](https://docs.github.com/en/authentication/connecting-to-github-with-ssh/adding-a-new-ssh-key-to-your-github-account) to add the server's SSH key to GitHub Authentication keys so you can clone private repositories.

### Step 6: Install BIENWorkflow 

Install the private R package `BIENWorkflow` and verify the installation. To address issues from the retirement of the spatial packages (`rgdal`, `rgeos`, `maptools`, and the associated`gdalUtils`), I made a few updates on `BIENWorkflow`:

1. Update the functions from `rgdal`, `rgeos` to `sf`.
2. Use `gdalUtilities` as a replacement for the outdated `gdalUtils`. 
